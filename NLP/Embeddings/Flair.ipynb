{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sentence\n",
    "sentence = Sentence('I love Berlin .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:13:08,100 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/NER-conll03-english/en-ner-conll03-v0.4.pt not found in cache, downloading to /tmp/tmpja4n6f17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432197603/432197603 [00:28<00:00, 15047069.65B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:13:37,457 copying /tmp/tmpja4n6f17 to cache at /home/user/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:13:37,891 removing temp file /tmp/tmpja4n6f17\n",
      "2019-06-09 19:13:38,068 loading file /home/user/.flair/models/en-ner-conll03-v0.4.pt\n"
     ]
    }
   ],
   "source": [
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"I love Berlin .\" - 4 Tokens]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"I love Berlin .\" - 4 Tokens\n",
      "The following NER tags are found:\n",
      "LOC-span [3]: \"Berlin\"\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print('The following NER tags are found:')\n",
    "\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 4 .\n",
      "Token: 4 .\n"
     ]
    }
   ],
   "source": [
    "# using the token id\n",
    "print(sentence.get_token(4))\n",
    "# using the index itself\n",
    "print(sentence[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 I\n",
      "Token: 2 love\n",
      "Token: 3 Berlin\n",
      "Token: 4 .\n"
     ]
    }
   ],
   "source": [
    "for token in sentence:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love Berlin <S-LOC> .\n"
     ]
    }
   ],
   "source": [
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I love Berlin .', 'labels': [], 'entities': [{'text': 'Berlin', 'start_pos': 7, 'end_pos': 13, 'type': 'LOC', 'confidence': 0.9992183446884155}]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:19:48,661 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpyrf9ohf6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000128/160000128 [00:22<00:00, 6987788.84B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:20:12,245 copying /tmp/tmpyrf9ohf6 to cache at /home/user/.flair/embeddings/glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:20:12,413 removing temp file /tmp/tmpyrf9ohf6\n",
      "2019-06-09 19:20:14,278 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmp48nxt0te\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21494764/21494764 [03:22<00:00, 106039.42B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:23:37,681 copying /tmp/tmp48nxt0te to cache at /home/user/.flair/embeddings/glove.gensim\n",
      "2019-06-09 19:23:37,711 removing temp file /tmp/tmp48nxt0te\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/user/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:23:39,217 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmp2093_h00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034624/73034624 [00:18<00:00, 3855534.81B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:23:58,844 copying /tmp/tmp2093_h00 to cache at /home/user/.flair/embeddings/news-forward-0.4.1.pt\n",
      "2019-06-09 19:23:58,919 removing temp file /tmp/tmp2093_h00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:24:00,230 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmp8v6z2qry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034575/73034575 [11:52<00:00, 102529.70B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:35:53,198 copying /tmp/tmp8v6z2qry to cache at /home/user/.flair/embeddings/news-backward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 19:35:53,280 removing temp file /tmp/tmp8v6z2qry\n"
     ]
    }
   ],
   "source": [
    "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
    "stacked_embeddings = StackedEmbeddings([\n",
    "                                        WordEmbeddings('glove'), \n",
    "                                        FlairEmbeddings('news-forward'), \n",
    "                                        FlairEmbeddings('news-backward'),\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 I\n",
      "tensor([-0.0465,  0.6197,  0.5665,  ..., -0.0040,  0.0220,  0.0052])\n",
      "Token: 2 love\n",
      "tensor([ 0.2598,  0.5583,  0.5799,  ..., -0.0039, -0.0130,  0.0047])\n",
      "Token: 3 Berlin\n",
      "tensor([ 6.9796e-01,  2.6999e-02,  6.8505e-02,  ..., -4.2759e-04,\n",
      "         4.4969e-04,  7.8760e-03])\n",
      "Token: 4 .\n",
      "tensor([-3.3979e-01,  2.0941e-01,  4.6348e-01,  ...,  8.8627e-06,\n",
      "         7.8450e-03,  3.3567e-03])\n"
     ]
    }
   ],
   "source": [
    "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"I love Berlin.\" - 3 Tokens]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import BertEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = BertEmbeddings()\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('I love Berlin.')\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 I\n",
      "tensor([ 0.3908,  0.7686, -0.4048,  ..., -0.1480,  0.3655,  0.1366])\n",
      "Token: 2 love\n",
      "tensor([ 1.1491,  0.9463,  0.8927,  ..., -0.4735,  0.5704,  0.1006])\n",
      "Token: 3 Berlin.\n",
      "tensor([ 0.6717, -0.4776, -0.3182,  ..., -0.5219, -0.0645, -0.2140])\n"
     ]
    }
   ],
   "source": [
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
